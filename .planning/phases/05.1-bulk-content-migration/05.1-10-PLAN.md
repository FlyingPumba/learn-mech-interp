---
phase: 05.1-bulk-content-migration
plan: 10
type: execute
wave: 2
depends_on: ["05.1-01"]
files_modified:
  - src/topics/sleeper-agent-detection/index.md
  - src/topics/sleeper-agent-detection/images/sleeper_agent_detection.png
  - src/topics/deception-detection/index.md
  - src/topics/safety-mechanisms-and-monitoring/index.md
  - src/topics/safety-mechanisms-and-monitoring/images/safety_applications_overview.png
  - src/topics/safety-mechanisms-and-monitoring/images/mi_safety_assessment.png
  - src/topics/mi-safety-limitations/index.md
autonomous: true

must_haves:
  truths:
    - "sleeper-agent-detection article covers the threat model, detection results, and the critical trained-vs-natural limitation"
    - "deception-detection article covers alignment faking and why behavioral evaluations fail"
    - "safety-mechanisms-and-monitoring article covers refusal direction recap, model organisms, sabotage evaluations"
    - "mi-safety-limitations article provides the honest scorecard of what MI can and cannot do for safety"
    - "All 4 articles have block: mi-for-safety"
  artifacts:
    - path: "src/topics/sleeper-agent-detection/index.md"
      provides: "Sleeper Agent Detection article"
      contains: "block: \"mi-for-safety\""
    - path: "src/topics/deception-detection/index.md"
      provides: "Deception Detection article"
      contains: "block: \"mi-for-safety\""
    - path: "src/topics/safety-mechanisms-and-monitoring/index.md"
      provides: "Safety Mechanisms article"
      contains: "block: \"mi-for-safety\""
    - path: "src/topics/mi-safety-limitations/index.md"
      provides: "MI Safety Limitations article"
      contains: "block: \"mi-for-safety\""
    - path: "src/topics/sleeper-agent-detection/images/sleeper_agent_detection.png"
      provides: "Sleeper agent detection diagram"
  key_links:
    - from: "src/topics/mi-safety-limitations/index.md"
      to: "src/topics/sleeper-agent-detection/index.md"
      via: "builds on all prior safety articles"
      pattern: "/topics/sleeper-agent-detection/"
---

<objective>
Create all 4 articles in Block 7 (MI for AI Safety) from Week 15: sleeper-agent-detection, deception-detection, safety-mechanisms-and-monitoring, and mi-safety-limitations.

Purpose: Block 7 applies MI methods to AI safety challenges, ending with an honest assessment of limitations. This is the "so what?" block that connects MI research to real safety concerns.
Output: 4 new articles + 3 diagrams from Week 15.
</objective>

<execution_context>
@/Users/ivan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ivan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/05.1-bulk-content-migration/05.1-RESEARCH.md
@src/_data/references.json (updated by Plan 01)
@src/_data/learningPath.json (updated by Plan 01)

Typst source file:
- /Users/ivan/latex/mech-interp-course/week-15/week-15.typ
- /Users/ivan/latex/mech-interp-course/globals.typ

Diagrams to copy:
- /Users/ivan/latex/mech-interp-course/week-15/assets/sleeper_agent_detection.png
- /Users/ivan/latex/mech-interp-course/week-15/assets/safety_applications_overview.png
- /Users/ivan/latex/mech-interp-course/week-15/assets/mi_safety_assessment.png
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create sleeper-agent-detection and deception-detection articles</name>
  <files>
    src/topics/sleeper-agent-detection/index.md
    src/topics/sleeper-agent-detection/images/sleeper_agent_detection.png
    src/topics/deception-detection/index.md
  </files>
  <action>
**Article A: sleeper-agent-detection**

Copy diagram:
```bash
mkdir -p src/topics/sleeper-agent-detection/images
cp /Users/ivan/latex/mech-interp-course/week-15/assets/sleeper_agent_detection.png src/topics/sleeper-agent-detection/images/
```

Create `src/topics/sleeper-agent-detection/index.md` from Week 15 section 3. Cover:

- The Sleeper Agent Threat Model: models that behave well during training but switch to harmful behavior when triggered
- Backdoors Survive Safety Training: Hubinger et al.'s finding that RLHF and SFT do not remove planted backdoors
- The Detection Result: internal probes can detect the difference between triggered and non-triggered model states
- Connection to Course Themes: this applies activation patching, probing, and representation analysis from earlier blocks
- CRITICAL LIMITATION: Trained vs Natural Deception: these results only apply to artificially trained backdoors, not to deception that might arise naturally during training
- Place the sleeper agent detection diagram

Front matter:
```yaml
title: "Detecting Sleeper Agents with Mechanistic Interpretability"
description: "How MI tools can detect artificially trained backdoor behaviors in language models, and the critical limitation that this does not extend to naturally arising deception."
prerequisites:
  - title: "The Refusal Direction"
    url: "/topics/refusal-direction/"
difficulty: "advanced"
block: "mi-for-safety"
category: "applications"
```

References: hubinger2024sleeper, anthropic2024probes. Cross-link to activation-patching, refusal-direction, forward to deception-detection.

**Article B: deception-detection**

Create `src/topics/deception-detection/index.md` from Week 15 section 4. Cover:

- What is Alignment Faking? A model that strategically behaves well during evaluation to avoid modification
- The Empirical Evidence: Greenblatt et al.'s Alignment Faking paper demonstrating the phenomenon
- Why Behavioral Evaluations Fail: if a model is faking alignment, behavioral tests cannot detect it by design
- Detection Efforts: internal probes can distinguish between genuine and strategic cooperation
- SAEs Fail as Deception Detectors: why dictionary learning approaches do not reliably detect deception

Front matter:
```yaml
title: "Deception Detection and Alignment Faking"
description: "The alignment faking threat and why behavioral evaluations fail to detect strategic deception, with early evidence that internal probes may succeed where behavior-based approaches cannot."
prerequisites:
  - title: "Detecting Sleeper Agents"
    url: "/topics/sleeper-agent-detection/"
difficulty: "advanced"
block: "mi-for-safety"
category: "applications"
```

References: greenblatt2024alignment. Cross-link to sleeper-agent-detection, forward to safety-mechanisms-and-monitoring.

Content guidelines: 1,500-2,000 words each, narrative prose, 2 pause-and-think, 2-4 sidenotes. These are sensitive topics -- present evidence carefully with appropriate caveats.
  </action>
  <verify>
Run `npx @11ty/eleventy --dryrun` -- no build errors. Verify sleeper agent PNG exists. Verify both articles exist.
  </verify>
  <done>sleeper-agent-detection and deception-detection articles created with the trained-vs-natural caveat clearly stated.</done>
</task>

<task type="auto">
  <name>Task 2: Create safety-mechanisms-and-monitoring and mi-safety-limitations articles</name>
  <files>
    src/topics/safety-mechanisms-and-monitoring/index.md
    src/topics/safety-mechanisms-and-monitoring/images/safety_applications_overview.png
    src/topics/safety-mechanisms-and-monitoring/images/mi_safety_assessment.png
    src/topics/mi-safety-limitations/index.md
  </files>
  <action>
**Article A: safety-mechanisms-and-monitoring**

Copy diagrams:
```bash
mkdir -p src/topics/safety-mechanisms-and-monitoring/images
cp /Users/ivan/latex/mech-interp-course/week-15/assets/safety_applications_overview.png src/topics/safety-mechanisms-and-monitoring/images/
cp /Users/ivan/latex/mech-interp-course/week-15/assets/mi_safety_assessment.png src/topics/safety-mechanisms-and-monitoring/images/
```

Create `src/topics/safety-mechanisms-and-monitoring/index.md` from Week 15 sections 5-6. Cover:

- The Refusal Direction Recap: brief review connecting to the refusal-direction article
- Model Organisms for Emergent Misalignment: using model organisms to study how misalignment might emerge
- Detection and Steering via the Misalignment Direction: analogous to the refusal direction but for misalignment
- Sabotage Evaluations: testing whether models can sabotage oversight mechanisms
- Attribution Graph Inspection: using circuit tracing for safety monitoring
- Limitations of monitoring approaches
- Place both diagrams

Front matter:
```yaml
title: "Understanding Safety Mechanisms and MI-Based Monitoring"
description: "How MI tools enable monitoring model behavior through internal representations, from refusal mechanisms to misalignment detection, and the practical limitations of these approaches."
prerequisites:
  - title: "Deception Detection and Alignment Faking"
    url: "/topics/deception-detection/"
difficulty: "advanced"
block: "mi-for-safety"
category: "applications"
```

References: hubinger2024sleeper. Cross-link to refusal-direction, circuit-tracing, forward to mi-safety-limitations.

**Article B: mi-safety-limitations**

Create `src/topics/mi-safety-limitations/index.md` from Week 15 sections 7-8. Cover:

- The Scorecard: what MI can and cannot currently do for safety
- Interpretability Illusions: features and circuits that appear meaningful but are artifacts
- Non-Identifiability: the same behavior can arise from many different circuits
- SAEs Discard Safety-Relevant Information: the sparsity constraint may throw away safety-critical signals
- Scalability: MI techniques that work on small models may not scale
- Per-Input vs Global Understanding: MI gives per-input explanations but safety needs global guarantees
- The Dual-Use Problem: MI tools that detect deception can also be used to create it
- The Gap: the distance between current MI capabilities and what AI safety actually needs

This is one of the most important articles in the course. It must be honest about limitations without being dismissive of the field.

Front matter:
```yaml
title: "Honest Limitations of MI for Safety"
description: "A candid assessment of what mechanistic interpretability cannot yet do for AI safety -- from interpretability illusions to scalability gaps -- and why closing these gaps matters."
prerequisites:
  - title: "Safety Mechanisms and MI-Based Monitoring"
    url: "/topics/safety-mechanisms-and-monitoring/"
difficulty: "advanced"
block: "mi-for-safety"
category: "core-concepts"
```

Cross-link to multiple prior articles (superposition, sparse-autoencoders, refusal-direction, circuit-tracing), forward to open-problems-methods.

Content guidelines: safety-mechanisms target 1,500-2,500 words. mi-safety-limitations target 2,000-2,500 words (substantial). 2 pause-and-think, 2-4 sidenotes each.
  </action>
  <verify>
Run `npx @11ty/eleventy --dryrun` -- no build errors. Verify 2 PNGs exist. Verify both articles exist.
  </verify>
  <done>safety-mechanisms-and-monitoring and mi-safety-limitations articles created. Block 7 complete with honest limitations clearly stated.</done>
</task>

</tasks>

<verification>
1. `npx @11ty/eleventy --dryrun` succeeds
2. All 4 Block 7 articles exist with block: "mi-for-safety"
3. 3 diagrams placed across the block
4. mi-safety-limitations covers at least 5 distinct limitations
5. Trained-vs-natural deception caveat is explicit in sleeper-agent-detection
</verification>

<success_criteria>
- 4 new articles from Week 15 covering MI for AI safety
- 3 diagrams placed with alt text and captions
- Honest limitations article is substantial and balanced
- Build succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/05.1-bulk-content-migration/05.1-10-SUMMARY.md`
</output>
