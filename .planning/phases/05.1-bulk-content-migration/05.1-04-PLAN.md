---
phase: 05.1-bulk-content-migration
plan: 04
type: execute
wave: 2
depends_on: ["05.1-01"]
files_modified:
  - src/topics/direct-logit-attribution/index.md
  - src/topics/logit-lens-and-probing/index.md
  - src/topics/logit-lens-and-probing/images/attn_induction.png
  - src/topics/logit-lens-and-probing/images/attn_prev_token.png
  - src/topics/logit-lens-and-probing/images/logit_lens_eiffel.png
autonomous: true

must_haves:
  truths:
    - "direct-logit-attribution article covers the DLA key insight, decomposition, per-token attribution, and reading attention patterns"
    - "logit-lens-and-probing article covers logit lens, tuned lens, probing (structural, MDL, amnesic), and the observation-vs-causation limitation"
    - "3 PNGs are placed in logit-lens-and-probing/images/ with alt text and Figure N: captions"
    - "Both articles have block: foundations-of-mi"
  artifacts:
    - path: "src/topics/direct-logit-attribution/index.md"
      provides: "Direct Logit Attribution article"
      contains: "block: \"foundations-of-mi\""
    - path: "src/topics/logit-lens-and-probing/index.md"
      provides: "Logit Lens, Tuned Lens, and Probing Classifiers article"
      contains: "block: \"foundations-of-mi\""
    - path: "src/topics/logit-lens-and-probing/images/logit_lens_eiffel.png"
      provides: "Logit lens example diagram"
  key_links:
    - from: "src/topics/direct-logit-attribution/index.md"
      to: "src/topics/induction-heads/index.md"
      via: "prerequisite link"
      pattern: "/topics/induction-heads/"
    - from: "src/topics/logit-lens-and-probing/index.md"
      to: "src/topics/activation-patching/index.md"
      via: "forward link to causal methods"
      pattern: "/topics/activation-patching/"
---

<objective>
Create Block 2 Part 2 (Foundations of MI): direct-logit-attribution from Week 4 and logit-lens-and-probing from Week 5, completing the 5 articles in Block 2.

Purpose: These articles cover the observational tools of MI (DLA, logit lens, probing) that precede the causal intervention methods in Block 3.
Output: 2 new articles + 3 diagram placements, completing Block 2.
</objective>

<execution_context>
@/Users/ivan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ivan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/05.1-bulk-content-migration/05.1-RESEARCH.md
@src/_data/references.json (updated by Plan 01)
@src/_data/learningPath.json (updated by Plan 01)

Typst source files:
- /Users/ivan/latex/mech-interp-course/week-04/week-04.typ (sections 6-7)
- /Users/ivan/latex/mech-interp-course/week-05/week-05.typ (sections 2-7)
- /Users/ivan/latex/mech-interp-course/globals.typ

Course research notes (READ THESE for deeper content, additional references, and pedagogical context beyond the Typst slides):
- /Users/ivan/latex/mech-interp-course/.planning/phases/03-core-concepts/03-RESEARCH.md (Weeks 3-5 domain research -- covers DLA, logit lens, tuned lens, probing critique)

Diagrams to copy:
- /Users/ivan/latex/mech-interp-course/week-05/assets/attn_induction.png
- /Users/ivan/latex/mech-interp-course/week-05/assets/attn_prev_token.png
- /Users/ivan/latex/mech-interp-course/week-05/assets/logit_lens_eiffel.png
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create direct-logit-attribution article</name>
  <files>src/topics/direct-logit-attribution/index.md</files>
  <action>
Create `src/topics/direct-logit-attribution/index.md` from Week 4 sections 6-7. Cover:

- Direct Logit Attribution: the key insight (each component's output can be projected onto the logit direction)
- The decomposition: how the residual stream decomposes into per-component contributions to the logit difference
- Per-token attribution: using DLA as a screening tool to identify which heads matter for a given task
- Reading Attention Patterns: common patterns (previous token, induction, duplicate token), limitations of attention pattern analysis alone (they show where info comes from, not what is computed)

Front matter:
```yaml
title: "Direct Logit Attribution"
description: "How to decompose a model's output into per-component contributions by projecting each attention head's output onto the logit difference direction."
prerequisites:
  - title: "Induction Heads and In-Context Learning"
    url: "/topics/induction-heads/"
difficulty: "intermediate"
block: "foundations-of-mi"
category: "methods"
```

References: elhage2021mathematical, wang2022ioi (for IOI as a DLA example). Cross-link to induction-heads (prereq), attention-mechanism (residual stream), forward to activation-patching (causal follow-up to DLA's observational approach).

Content guidelines:
- Target 1,500-2,500 words
- Convert Typst math to KaTeX (DLA involves logit difference: `\text{logit}(A) - \text{logit}(B)`)
- Blockquote definitions for DLA, logit difference
- 2 pause-and-think prompts
- 2-4 sidenotes
- End with the limitation: DLA shows correlation, not causation -- motivating Block 3
  </action>
  <verify>
Run `npx @11ty/eleventy --dryrun` -- no build errors. Verify file exists.
  </verify>
  <done>direct-logit-attribution article exists with complete front matter, narrative prose, KaTeX math, citations, and the observational-vs-causal framing.</done>
</task>

<task type="auto">
  <name>Task 2: Create logit-lens-and-probing article with 3 diagrams</name>
  <files>
    src/topics/logit-lens-and-probing/index.md
    src/topics/logit-lens-and-probing/images/attn_induction.png
    src/topics/logit-lens-and-probing/images/attn_prev_token.png
    src/topics/logit-lens-and-probing/images/logit_lens_eiffel.png
  </files>
  <action>
First, create the images directory and copy diagrams:
```bash
mkdir -p src/topics/logit-lens-and-probing/images
cp /Users/ivan/latex/mech-interp-course/week-05/assets/attn_induction.png src/topics/logit-lens-and-probing/images/
cp /Users/ivan/latex/mech-interp-course/week-05/assets/attn_prev_token.png src/topics/logit-lens-and-probing/images/
cp /Users/ivan/latex/mech-interp-course/week-05/assets/logit_lens_eiffel.png src/topics/logit-lens-and-probing/images/
```

Then create `src/topics/logit-lens-and-probing/index.md` from Week 5 sections 2-7. Cover:

- The Logit Lens: applying the unembedding matrix at intermediate layers to see what the model "believes" at each layer
- The Tuned Lens: Belrose et al.'s improvement -- learned affine probes per layer for better predictions
- Probing classifiers: the promise (can we read internal representations?), structural probes (Hewitt & Manning), MDL probing (Voita & Titov), amnesic probing (Elazar et al.)
- The critique of probing: what does a probe's success actually tell us?
- The key limitation: all these methods are observational -- they show correlation, not causation. This motivates the transition to causal methods (activation patching in Block 3)

Place all 3 diagrams with alt text and Figure N: captions:
- `![Induction head attention pattern showing the characteristic stripe pattern](/topics/logit-lens-and-probing/images/attn_induction.png "Figure 1: Induction head attention pattern...")`
- `![Previous token head pattern showing diagonal attention](/topics/logit-lens-and-probing/images/attn_prev_token.png "Figure 2: Previous token head attention pattern...")`
- `![Logit lens applied to predict the Eiffel Tower token](/topics/logit-lens-and-probing/images/logit_lens_eiffel.png "Figure 3: The logit lens applied layer by layer...")`

Front matter:
```yaml
title: "The Logit Lens, Tuned Lens, and Probing Classifiers"
description: "Observational tools for reading model internals -- from the logit lens to probing classifiers -- and the fundamental limitation that observation alone cannot establish causation."
prerequisites:
  - title: "Direct Logit Attribution"
    url: "/topics/direct-logit-attribution/"
difficulty: "intermediate"
block: "foundations-of-mi"
category: "methods"
```

References: nostalgebraist2020logitlens, belrose2023tunedlens, hewitt2019structural, voita2020mdl, elazar2021amnesic, belinkov2022probing. Cross-link forward to activation-patching (the causal answer to observational limitations).

Content guidelines:
- Target 2,000-2,500 words (this article covers more ground)
- Convert Typst math to KaTeX
- Blockquote definitions for logit lens, tuned lens, probing classifier
- 2 pause-and-think prompts
- 2-4 sidenotes
- Build narrative arc: observation tools -> their limits -> need for causation
  </action>
  <verify>
Run `npx @11ty/eleventy --dryrun` -- no build errors. Verify all 3 PNGs exist in the images directory. Verify article has Figure references.
  </verify>
  <done>logit-lens-and-probing article exists with 3 placed diagrams, complete front matter, narrative prose covering the full observational toolkit, and the causation limitation framing.</done>
</task>

</tasks>

<verification>
1. `npx @11ty/eleventy --dryrun` succeeds
2. Both articles exist with valid front matter (block: "foundations-of-mi")
3. 3 PNGs exist in src/topics/logit-lens-and-probing/images/
4. logit-lens-and-probing references at least 4 papers via {% cite %}
5. Both articles end with forward-links to causal methods
</verification>

<success_criteria>
- 2 new articles completing Block 2 (5 total articles in Foundations of MI)
- 3 diagrams placed with alt text and captions
- Narrative arc from observation to causation clearly established
- All front matter valid, build succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/05.1-bulk-content-migration/05.1-04-SUMMARY.md`
</output>
