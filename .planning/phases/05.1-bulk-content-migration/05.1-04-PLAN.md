---
phase: 05.1-bulk-content-migration
plan: 04
type: execute
wave: 2
depends_on: ["05.1-01"]
files_modified:
  - src/topics/observational-tools/index.md
  - src/topics/observational-tools/images/attn_induction.png
  - src/topics/observational-tools/images/attn_prev_token.png
  - src/topics/observational-tools/images/logit_lens_eiffel.png
  - src/topics/activation-patching/index.md
autonomous: true

must_haves:
  truths:
    - "observational-tools article covers logit lens, tuned lens, probing classifiers, and attention pattern visualization with 3 diagrams"
    - "activation-patching pilot covers all Week 6 content with no significant gaps"
    - "All 3 PNGs placed with alt text and Figure N captions"
  artifacts:
    - path: "src/topics/observational-tools/index.md"
      provides: "Week 5 content as narrative article"
      contains: "block: \"foundations-of-mi\""
    - path: "src/topics/observational-tools/images/logit_lens_eiffel.png"
      provides: "Logit lens example diagram"
    - path: "src/topics/activation-patching/index.md"
      provides: "Complete Week 6 coverage"
      contains: "block: \"observation-to-causation\""
  key_links:
    - from: "src/topics/observational-tools/index.md"
      to: "src/topics/induction-heads/index.md"
      via: "cross-link to DLA and induction head concepts"
      pattern: "/topics/induction-heads/"
    - from: "src/topics/observational-tools/index.md"
      to: "src/topics/activation-patching/index.md"
      via: "forward link to causal methods"
      pattern: "/topics/activation-patching/"
---

<objective>
Complete Block 2 Part 2 and review Block 3 Part 1: create the observational-tools article (Week 5, 3 PNGs) and review/expand the activation-patching pilot (Week 6).

Purpose: These articles complete the progression from observation to causation. Observational tools (logit lens, probing) show what models represent; activation patching shows how to test causal hypotheses. Together they bridge passive observation and active intervention.
Output: 1 new article (observational-tools with 3 diagrams) + 1 reviewed/expanded article (activation-patching)
</objective>

<execution_context>
@/Users/ivan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ivan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/05.1-bulk-content-migration/05.1-RESEARCH.md

Source content:
@/Users/ivan/latex/mech-interp-course/week-05/week-05.typ
@/Users/ivan/latex/mech-interp-course/week-06/week-06.typ
@/Users/ivan/latex/mech-interp-course/globals.typ

Existing article to review:
@src/topics/activation-patching/index.md

Data files (already updated by Plan 01):
@src/_data/references.json
@src/_data/learningPath.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create observational-tools article from Week 5</name>
  <files>
    src/topics/observational-tools/index.md
    src/topics/observational-tools/images/attn_induction.png
    src/topics/observational-tools/images/attn_prev_token.png
    src/topics/observational-tools/images/logit_lens_eiffel.png
  </files>
  <action>
Create directory, copy images, and write article:
```bash
mkdir -p src/topics/observational-tools/images
cp /Users/ivan/latex/mech-interp-course/week-05/assets/attn_induction.png src/topics/observational-tools/images/
cp /Users/ivan/latex/mech-interp-course/week-05/assets/attn_prev_token.png src/topics/observational-tools/images/
cp /Users/ivan/latex/mech-interp-course/week-05/assets/logit_lens_eiffel.png src/topics/observational-tools/images/
```

Convert week-05.typ (801 lines) into a narrative long-form article. Week 5 covers:

1. **The Logit Lens** - nostalgebraist's technique: projecting intermediate residual stream states through the unembedding matrix. What it reveals about how predictions form across layers. Limitations (representation drift).

2. **The Tuned Lens** - Belrose et al.'s improvement: learning affine probes per layer. Better calibrated than logit lens. Connection to the "prediction at every layer" hypothesis.

3. **Probing Classifiers** - Training linear (or simple nonlinear) classifiers on activations to detect specific features. Hewitt & Manning structural probes. The "probing vs memorization" debate (Voita & Titov MDL probing, Elazar amnesic probing). Belinkov survey.

4. **Attention Pattern Visualization** - Reading and interpreting attention heatmaps. Common patterns: previous-token heads, induction heads, positional heads. What attention patterns can and cannot tell us.

Front matter:
```yaml
---
title: "Observational Tools: Looking Inside the Model"
description: "A survey of non-causal techniques for inspecting transformer internals -- the logit lens, tuned lens, probing classifiers, and attention pattern visualization."
prerequisites:
  - title: "The Attention Mechanism"
    url: "/topics/attention-mechanism/"
  - title: "Induction Heads and In-Context Learning"
    url: "/topics/induction-heads/"
difficulty: "intermediate"
block: "foundations-of-mi"
category: "methods"
---
```

Image placement (use markdown-it-figure syntax):
```markdown
![Attention pattern showing previous-token head behavior](/topics/observational-tools/images/attn_prev_token.png "Figure 1: A previous-token head attention pattern. Each token attends primarily to the token immediately before it.")

![Attention pattern showing induction head behavior](/topics/observational-tools/images/attn_induction.png "Figure 2: An induction head attention pattern showing the [A][B]...[A] -> attend to [B] pattern.")

![Logit lens output showing next-token predictions across layers](/topics/observational-tools/images/logit_lens_eiffel.png "Figure 3: The logit lens applied to a prompt about the Eiffel Tower, showing how the model's top prediction evolves across layers.")
```

Content guidelines:
- Narrative prose, not bullet fragments
- Cite: nostalgebraist2020logitlens, belrose2023tunedlens, hewitt2019structural, voita2020mdl, elazar2021amnesic, belinkov2022probing (all in references.json)
- Translate all math from Typst to KaTeX
- 2 pause-and-think prompts
- 2-4 sidenotes
- Cross-link to induction-heads (DLA, attention patterns), attention-mechanism (residual stream)
- Cross-link forward to activation-patching (causal methods as next step)
- Target 1,500-2,500 words
  </action>
  <verify>Run `npx @11ty/eleventy` and check build succeeds. Verify all 3 images render in the article. Check alt text and captions are present. Verify citations resolve.</verify>
  <done>observational-tools article exists with 3 placed images, complete front matter, narrative prose covering logit lens, tuned lens, probing, and attention patterns. All citations and cross-links work.</done>
</task>

<task type="auto">
  <name>Task 2: Review and expand activation-patching pilot article</name>
  <files>src/topics/activation-patching/index.md</files>
  <action>
Compare the existing activation-patching pilot article (~180 lines) against week-06.typ (800 lines) section by section.

Check that these Week 6 topics are covered:
- Clean/corrupted run framework
- Noising vs denoising patching
- Activation patching at different granularities (layer, head, position)
- Worked example with IOI task
- Attribution patching (gradient-based approximation)
- Path patching
- Connection to causal inference concepts

The research says the pilot is "likely complete." If so, make minimal changes. If gaps exist, expand with narrative prose converted from Typst.

Ensure front matter is complete and correct:
- title, description, prerequisites, difficulty: "advanced", block: "observation-to-causation", category: "methods"

Add cross-links to observational-tools (as the observational counterpart), ioi-circuit (full case study), and superposition (polysemanticity challenges for patching).

Ensure 3 existing images still have proper alt text and Figure N captions.
  </action>
  <verify>Run `npx @11ty/eleventy` and verify build succeeds. Check activation-patching article renders correctly with all images, math, and citations.</verify>
  <done>activation-patching article covers all Week 6 content. Front matter complete. Cross-links to observational-tools and ioi-circuit present. All 3 images render with alt text and captions.</done>
</task>

</tasks>

<verification>
1. `npx @11ty/eleventy` builds without errors
2. observational-tools appears in sidebar under "Foundations of MI" block (third topic)
3. activation-patching remains in sidebar under "Observation to Causation" block
4. 3 new PNGs render correctly in observational-tools article
5. 3 existing PNGs still render in activation-patching article
6. No KaTeX errors, no [??] citation markers
7. Cross-links between the two articles work
</verification>

<success_criteria>
- observational-tools is a complete, readable article with 3 diagrams covering all Week 5 topics
- activation-patching covers all Week 6 content (verified against Typst source)
- Both have complete front matter, valid KaTeX, working citations and cross-links
- All 6 images (3 new + 3 existing) render correctly
</success_criteria>

<output>
After completion, create `.planning/phases/05.1-bulk-content-migration/05.1-04-SUMMARY.md`
</output>
